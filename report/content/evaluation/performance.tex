\section{Performance Testing}\label{sec:evalperformance}
This section is about the performance of the two different scheduling methods used: greedy scheduling and LP scheduling. The purpose of the performance test is to see how well the two scheduling methods scale and to calculate how many charge-offers they can schedule in a time slot (e.g.\ 20 min). To test the speed of the schedulers, we evaluate how fast they can schedule a given amount of charge-offers. To test the performance, two experiments will be conducted. One to test the greedy scheduler and one to test the LP scheduler. The setup for the two test are identical. The tests were all run on a system with the following specifications:

\begin{itemize}
    \item OS X v10.8 Mountain Lion
    \item \SI{2.9}{\giga\hertz} quad-core Intel Core i5-3470S processor with \SI{6}{\mega\byte} L3 cache
    \item \SI{8}{\giga\byte} \SI{1600}{\mega\hertz} DDR3 memory
\end{itemize}

The general setup is a loop that increases the number of charge-offers added to the scheduling method being tested. The ratio between energy production and consumption is static throughout the experiments. This is done to ensure that the resulting schedules will be somewhat similar. The execution time of the scheduling is measured using two timestamps: one just before and one just after the scheduling call. The execution time is given in seconds. There is a difference in the experiment for the greedy scheduler and in the LP scheduler in terms of the size of the input. Because the greedy scheduler is that much faster, it can handle larger inputs. The LP scheduler is also limited by the memory of the computer, as it requires a lot of memory, so increasing memory size could potentially greatly increase the LP scheduling performance. 

\subsection{Linear Programming Performance}\label{subsec:lpperfromance}  
The performance of the LP scheduler is tested up to \num{50000} charge-offers, because a greater amount of charge-offers are simple too time consuming. The resulting performance test results can be seen in \Cref{fig:performance_lp}. The gathering of these data points include the time it takes to write to and read from a file from Java.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=\textwidth]{drawings/testresults/lpperformance.tikz}
    \caption{Performance test of LP scheduling}\label{fig:performance_lp}
\end{figure}

This graph shows that LP scheduler can schedule about \num{44000} charge-offers in a time slot. A curve fit for the LP scheduler's function of input size based on our measurements is:

\[ \mathop{timeLP}(\var{x}) = 0.00121779 \cdot x^2 - 31.856 \cdot x + 243330 \]

where $x$ is the amount of EVs, with the coefficient of determination ($R^2$) equal to \num{0.987038}. 

\subsection{Greedy performance}\label{subsec:gsperformance} 
The performance of the greedy scheduler is tested with up to \num{200000} charge-offers. The resulting performance test results can be seen in \Cref{fig:performance_gs}.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=\textwidth]{drawings/testresults/gsperformance.tikz}
    \caption{Performance test of greedy scheduling}\label{fig:performance_gs}
\end{figure}

The graph shows that greedy scheduler can schedule about \num{200000} charge-offers in 11 minutes. The greedy schedulers function of input size is computed as:

\[ \mathop{timeGS}(\var{x}) = 1.97809 \cdot 10^{-5} \cdot x^2 - 0.994425 \cdot x + 44653.3 \]

where $x$ is the amount of EVs, with the coefficient of determination ($R^2$) equal to \num{0.995229}. From this function we can then compute that the greedy scheduler can schedule up to \num{268000} charge-offers in a 20 minute time slot.

\subsection{Conclusion}
The clear winner in the performance test is the greedy scheduler. It can schedule roughly 6 times as many charge-offers as the LP scheduler in a time slot, but it also scales better as can be seen look at the slope of the curves. The slope of the curve for LP scheduling is a lot steeper than the slope of the curve for greedy scheduling.

We will now perform tests on our forecasting models to see which one is best for our system. 

