\section{Future Work}\label{sec:conclusion:future-work}

From the conclusion we found that there are some requirements, 
from the requirement specification presented in \Cref{sec:requirements-specification}, 
that are only partially fulfilled, 
and in the evaluation of the system in \Cref{chap:evaluation}, 
we found that there are parts of the system that does not work as well as intended.

Based on this we can formulate the points described below for improving the system or further develop it.

\subsection{Use a Wearable}

In order to prototype and test the concepts and technologies combined in the system, 
\eg indoor positioning, gesture recognition, and orientation of the user, 
the system was developed for a smartphone.
This was chosen because we already had access to multiple smartphones, 
that could be used to test the system, 
but had no access to a wearable that fit our needs.

Instead of spending money on an expensive wearable, 
and time on getting to know yet another platform, 
it was faster for us to prototype the solution on a smartphone.

In order to get the full benefit of the system, 
\ie the convenience of controlling a smart home by performing gestures, 
without of being near a smartphone, 
the system should be ported to a wearable, 
and only rely on a smartphone for the situations where it is absolutely needed, if needed at all.

\subsection{Unify the Server and the Hub}

The server used as a medium for communicating with HomePort, 
is currently a standalone piece of software. 
Ideally this should be bundled with the hub. 
By doing so, we can reduce the amount of programs running in each household using the system. 
Unifying the server and the hub means that only one piece of software must be configured and started.

As the solution is built on HomePort, which is open source, 
the server can be bundled with HomePort.

\subsection{Investigate Alternatives for Indoor Positioning}

In \Cref{sec:estimoteprecision} we presented results showing Estimotes low accuracy, 
when performing indoor positioning, 
and in \Cref{sec:evaluation:system-correctness} we showed the consequences of this inaccuracy.

It would be interesting to investigate, 
if there are better solutions for indoor positioning, 
than the one provided by Estimote.
Alternatives that may be worth considering, 
include solutions based on ultra wideband (UWB), 
such as Pozyx or DecaWave described in \Cref{sec:analysis:indoor-positioning}.
UWB have been reported to have accuracy of below \SI{0.3}{\meter} \cite{Liu:4343996}.

In order to achieve the the desired accuracy of \perc{80}, 
as described in the requirement specification, 
the solution used for indoor positioning must have an inaccuracy of about \SI{0.6}{\meter}
as described in \Cref{sec:evaluation:system-correctness}.

\subsection{Include Information About the Users Context}

An alternative to precise user positioning, 
\ie tracking of a user inside a room, 
is to include other information about the context the user operates in.

Together with the orientation of the user, 
the position of the user is used to determine which device the user points at, 
and thus which device to send an action to. 
This means the position of the user and his orientation provide some information about the context, 
in which the user operates. 
Since we found the position of the user to be inaccurate, 
it may be interesting to look at other information about the context of the user.

By excluding the position if the user, 
we are no longer able to create a solution, 
in which the user points at a smart device in order to control it, 
but this may not be necessary in order to provide a good user experience. 
Given a broad amount of data about the user's context, 
we may be able to determine or narrow the set of devices the user desires to control. 
For example, it may be that users are more likely to control devices, 
that are in the same room as themselves. 
Estimote or other indoor positioning technologies should be able to determine which room a user is in, 
with a higher accuracy than a granular position of the user. In this case we may be able utilize the region monitoring as described in \Cref{sec:design:indoor-positioning}.

If a smart device, that is in the same room as the user, 
supports the gesture performed by the user, 
the smart device receives the appropriate action. 
If not, we look in the entire system across all rooms for devices that supports the gesture.
This will likely require more unique gestures than in our system,
but if we only consider one room at a time, 
this number is still manageable.

Other information about the context may be the state of other devices in the system, 
devices the user has recently controlled, 
patterns of the users behavior throughout his day, 
or data provided by other sensors in the system.

These are ideas that may be worth exploring. 

\subsection{Configuration of Locations}

Should the project continue to use Estimote, 
or similar products for indoor positioning, 
a solution for configuring locations should be implemented. 
In \Cref{sec:design:indoor-positioning:configuration-of-locations} we proposed a design for configuring locations for use with Estimote. 

Due to time constraints, 
the low complexity of the feature and its little contribution to the core of the project, 
the designed solution was not implemented. 
If the solution implemented during the project was released as a product for end users, 
this should be implemented in order to ease the setup for the user.

\subsection{Improve Detection of Pointing}

As described in the evaluation of detecting points in \Cref{sec:evaluation:pointing}, 
there are issues with the point detector. 
It is currently too slow, 
and detects points if the phone is lying on a table that is subject to vibrations (from \eg a stereo og a desktop computer).

Future work could look into reducing the length of the sampling period. 
Furthermore future work could look into better detecting if a device is ``idle'', 
\ie if it laying still on \eg a table. 
This issue may become more critical when using a wearable device. 
For example, if the system is implemented on a smartwatch, 
there are several states to consider. 
The hand may be held still because the user is not moving, 
it may be moving slightly because the user is typing on a computer, 
or it may be moving even more because the user is walking. 
Lastly, the wearable may be held still because the user is pointing. 
There are many cases to consider.

\subsection{Continuous Recognition of Gestures}

Another interesting aspect to investigate, 
is to eliminate the need of starting and stopping a gesture by performing a point. 
In the \threedollar example application, 
a button was used to start and stop the gesture. 
The user would press ``Start'' to perform the gesture, 
and then press ``Stop'' when the gesture was finished. 
In this project we replaced this button with a point. 
The user must start a gesture by pointing, 
perform the gesture, 
and then point again to end the gesture. 
While this is arguably better than pressing a button, 
this is not ideal.

Ideally we would like to be able to do gesture recognition on a \emph{continuous stream} of data from the accelerometer. 
By doing so, we eliminate the need to explicitly start and stop a gesture.
This could, however, easily become very costly for to perform for wearables,
both in terms of CPU, but also battery.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../../master"
%%% End:
